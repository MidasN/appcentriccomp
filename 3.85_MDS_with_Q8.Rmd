
# I am adding Q8v_2_* questions to MDS in this Script


## Q4-Q7 are questions regarding soft on different devices
## DF with all the software items


```{r}

library(tidyverse)
library(magrittr)
library(tidyLPA)

library(ggplot2)
library(ggpubr)

library(mclust)
library(forcats)
library(hrbrthemes)

source("./functions.R")

```

Showing job shifts in connection with associated software is not possible due to NAs in Q21_1_open (previous job)
TODO: transition plots for jobs
TODO: transition plots for education

```{r}

df_clean$Q18_1_open %>% as.factor() %>% summary()
df_clean$Q21_1_open %>% as.factor() %>% summary()

df_clean$profile_education %>% summary

# Q18_1_open:Q18_a - job title + tasks description
# Q21_1_open:Q22 - previous job titles + tasks description

```

Here I am excluding timing columns


```{r}

df_clean %<>%
  dplyr::select(-c(page_pSC1_timing:tot_time))

# df_clean %>% nrow
na_vector = apply(df_clean, 2, function(x){

  sum(is.na(x))

})

na_vector[na_vector > 0] # which variables produce most of the NAs
df_final = df_clean %>% dplyr::select(
                                      names(na_vector[na_vector == 0]),
                                      -Occupation_Num, -status, -Occupation_DISCO,
                                      -c(Q85a_1_1, Q85a_2_1, Q85a_3_1, Q85a_4_1),
                                      -c(Q21_1_open, Q22),
                                      -c(Q18_1_open, Q18a),
                                      -c(comments, Q4, Q5, Q6, Q7))


df_final %>% nrow
df_final %>% ncol

```

Based on the info about NAs in the following chunk I updated columns.csv
UPD: not necessary right now 

```{r}

# FIXME: ?set not_mentioned?

# Q24 - what industry do you work in
# Q21 - what was your last (main) job titled
# Q23 Did you work in the public or private sector
# Q85_4_5: Mobile phone: other
# Q85_4_6: Mobile phone: Blackbery OS

# Less than 150 NAs:
# Q20 - what industry do you work in
# Q18 - what is your position/job title
# Q19 - do you work in a public/private sector


```

Reordering variables to make values semi-continuous


```{r}

df_final$Q9[df_final$Q9 == 4] = 0
df_final$Q10[df_final$Q10 == 4] = 0
df_final$Q11[df_final$Q11 == 4] = 0
df_final$Q12[df_final$Q12 == 4] = 0
df_final$Q13[df_final$Q13 == 4] = 0
df_final$Q14[df_final$Q14 == 4] = 0
df_final$Q15[df_final$Q15 == 4] = 0
df_final$Q16[df_final$Q16 == 4] = 0

df_final$Q17_R = 6 - df_final$Q17


```

Description of items for LPA

```{r}

# Q1 - language

# TODO: ask about numbers
# Q3_1 - Desktop
# Q3_2 - Laptop
# Q3_3 - Tablet
# Q3_4 - Mobile phone/Smartphone
#

# Q8_v2_1 - Built-in default settings
# Q8_v2_2 - Plugins/add-ons/extensions
# Q8_v2_3 - Script to extend Software
# Q8_v2_4 - I reprogram

# Traditional Surveys
# Q9 - digital collaboration skills
# Q10 - digital communication skills
# Q11 - production of digital content
# Q12 - formatting/edditing skills
# Q13 - programming languages knowledge
# Q14 - problem-solving skills produced by digital technologies
# Q15 - understanding of underlying logic of software and problem-solving
# Q16 - updating IT skills


# Q17_R - employment 



```



# Here I am filtering software out of the top 9

```{r}


jobtitleanddescription <- df_clean[, c("RecordNo", "Q18_1_open", "Q18a", "Occupation_DISCO", "Occupation")]


merged <- merge(x = software_cleaned[!(software_cleaned$a2 %in% (software_aggregated %>% top_n(9, n) %$% a2)),], # throwing away top 9
                y = jobtitleanddescription,
                by = "RecordNo") %>%
  select(-a, -Q18_1_open, -Q18a, -Occupation_DISCO)





```


# TODO: remake the table with a `q` per `a2`
# FIXME: what I was doing wrong before I have not excluded repeated items per respondent
# Fixing it


```{r}


merged_quas = merged[!is.na(merged$a2), ] %>% # removing NA's from the a column
  dplyr::rename(a = a2) %>% # FIXME: loosing the information about the device used
  select(-q)

merged_quas = merged_quas %>%
  group_by(RecordNo, a) %>%
  mutate(n = n()) %>% dplyr::filter(n < 2) %>% dplyr::select(-n) %>%
  ungroup() # moving out duplicates produced by Q4- and so on quesions


```


adding Q8 questions with quasi-ordinal scale

```{r}

# df_clean %>% colnames()

df_quas = df_clean %>% select(RecordNo, Q8_v2_1:Q16)

# anti_join(df_quas, merged_quas, by = "RecordNo") %>% View # 180 respondents are missing

df_merged_quas = inner_join(df_quas, merged_quas, by = "RecordNo")
# df_merged_quas %>% View


```

# FIXME: think about how to adjust number of users
# UPD: simple decision might be just to throw away software which is used less than by 5 respondents in the sample

```{r}

pre_dist_multi = df_merged_quas %>% select(-Occupation) %>% 
  group_by(a) %>% 
  mutate_at(vars(Q8_v2_1:Q16),
            funs("agr" = sum(.))) %>% mutate(n = n()) %>%
  mutate_at(vars(Q8_v2_1_agr:Q16_agr),
                   funs("norm" = . / n)) %>% 
  select(-c(Q8_v2_1_agr:Q16_agr),
         -c(Q8_v2_1:Q16))  %>%
  dplyr::rename(respondents_quant = n)  %>%
  filter(row_number() == 1)  %>%
  ungroup() %>%  arrange(desc(respondents_quant)) # %>% View


# pre_dist_multi$a %>% as.factor() %>% summary()
pre_dist_multi %>% View


```

```{r}

pre_dist_occupations = df_merged_quas %>%
  gather(key, val, Occupation) %>% 
  dplyr::select(a, key, val) %>% 
  group_by(a, val) %>% tally() %>%
  spread(val, n, fill = 0)  %>%
  ungroup()


# pre_dist_occupations$a %>% as.factor() %>% summary()

```

```{r}

pre_dist_multi_final = inner_join(pre_dist_multi, pre_dist_occupations, by = "a")


```


# Pre-MDS data preparation
Scaling Before MDS, results are even worse
# UPD: scaling should be accomplished for all of the vars, another fix

```{r}

pre_dist_multi_final %>% colnames()

## scaling only for occupations since they represent absolute frequencies

pre_dist_multi_final[,-c(1:16)] %<>% apply(2, function(X) scale(X))


# pre_dist_multi_final[,-c(1:3)] %<>% apply(2, function(X) scale(X, center = FALSE))

pre_dist_multi_final %>% View
## pre_dist_multi_final$a %>% as.factor() %>% summary()

```


## MDS

Labels to put on the map

```{r}


pre_dist_multi_final %>% colnames

labels_to_select = software_cleaned$a2[!(software_cleaned$a2 %in% (software_aggregated %>% top_n(9, n) %$% a2))][1:50]

```

MDS

```{r}

library(skimr)
skimr::skim(pre_dist_multi_final[,-c(1, 16:ncol(pre_dist_multi_final))] %>% select(-respondents_quant))

set.seed(33)
# "euclidean" 'maximum' 'manhattan' 'minkowski' 'canberra' 'binary'

source("./functions.R")

# manhattan is good
# canberra - great division

pre_dist_multi_final %>% colnames

## only for survey items
with(dev.new(), mds_n_plot(pre_dist_multi_final[,-c(1, 16:ncol(pre_dist_multi_final))] %>% select(-respondents_quant),
                                                "canberra",
                                                labels_to_select,
                                                7))




with(dev.new(), mds_n_plot(pre_dist_multi_final[,-c(1)] %>% select(-respondents_quant),
                                                "canberra",
                                                labels_to_select,
                                                5))


```

```{r}

method = "canberra"
clust_n = 5

pre_dist = pre_dist_multi_final[,-c(1, 16:ncol(pre_dist_multi_final))] %>% select(-respondents_quant)

d = dist(pre_dist[,-1],
         method = method)
fit = cmdscale(d, k = 2)

fit_tb = fit %>% as_tibble()
colnames(fit_tb) = c("Dim.1", "Dim.2")


x = fit[, 1]
y = fit[, 2]

set.seed(11)
kmeans_output = kmeans(fit_tb, clust_n)

clust = kmeans_output$cluster ## FIXME: delete global declaration

clust_centers = kmeans_output$centers[,-3] %>% as.data.frame()
colnames(clust_centers)[1:2] = c("Dim.1.c", "Dim.2.c")

clust_centers %<>% mutate(groups = rownames(clust_centers) %>% as.character())

# clust_centers

fit_tb = fit_tb %>% # making it global for later use in for_labels df
  mutate(groups = clust %>% as.character(),
         index = 1:nrow(fit_tb))



fit_tb = inner_join(fit_tb, clust_centers, by = "groups")
# fit_tb$groups %<>% as.factor()

fit_tb %>% View

## combining 6 labels per group which contains highest scores on each dimension
## TODO: grab with lowest as well

fit_tb %<>%
  group_by(groups) %>%
  mutate(dist = sqrt((Dim.1 - Dim.1.c)^2 + (Dim.2 - Dim.2.c)^2),
         abs_dist = abs(Dim.1 - Dim.1.c) + (Dim.2 - Dim.2.c))

index_labels_balanced = c(
  fit_tb %>% group_by(groups) %>% arrange(dist, .by_group = TRUE) %>% filter(row_number() %in% (1:12)) %$% index)

## fit_tb %>% group_by(groups) %>% arrange(dist, .by_group = TRUE) %>% View
## index_labels_balanced = c(
##   fit_tb %>% arrange(abs_dist) %>% filter(row_number() %in% (1:12)) %$% index)


fit_tb %>% arrange(dist) %>% filter(row_number() %in% (1:6)) %>% View
## index_labels_balanced = c(
##   fit_tb %>% mutate(index = 1:nrow(fit_tb)) %>% group_by(groups) %>% arrange(desc(Dim.1)) %>% filter(row_number() %in% c(1:3)) %$% index,
##   fit_tb %>% mutate(index = 1:nrow(fit_tb)) %>% group_by(groups) %>% arrange(desc(Dim.2)) %>% filter(row_number() %in% c(1:3)) %$% index,
##   fit_tb %>% mutate(index = 1:nrow(fit_tb)) %>% group_by(groups) %>% arrange(Dim.1) %>% filter(row_number() %in% c(1:3)) %$% index,
##   fit_tb %>% mutate(index = 1:nrow(fit_tb)) %>% group_by(groups) %>% arrange(Dim.2) %>% filter(row_number() %in% c(1:3)) %$% index)


index_labels_balanced = index_labels_balanced[!duplicated(index_labels_balanced)]
index_labels_balanced

fit_tb %>% ungroup() %>% arrange(index) %>% View
# %>% View

ggscatter(fit_tb %>% ungroup() %>% arrange(index),
          x = "Dim.1", y = "Dim.2",
          label = pre_dist_multi_final$a,
          label.select = pre_dist_multi_final$a[index_labels_balanced],
          color = "groups",
#          star.plot = TRUE,
          palette = "jco",
          size = 1,
          ellipse = TRUE,
          ellipse.type = "convex",
          repel = TRUE) + geom_point(data = clust_centers, aes(x = Dim.1.c, y = Dim.2.c, size = 13))

# fit_tb[!duplicated(fit_tb$groups),] %>% View

pre_dist_multi_final %>% View

with(dev.new(), mds_n_plot(pre_dist_100, "canberra", labels_to_select, 6))

with(dev.new(), mds_n_plot(pre_dist_200, "manhattan", labels_to_select, 6))


```
